+++
title = "pix2pix算法"
date = 2018-06-07T13:17:26+08:00
draft = false
summary = "利用GAN完成的pix2pix图像翻译算法学习"

tags = ["pix2pix","GAN"]
categories = ["Machine Learning"]

[header]
image = ""
caption = ""
preview = true

+++

### 人工智能大作业2018：涂鸦上色问题



#### 作业思路

将涂鸦视作是完整的图画的边缘提取的产物

1. 随机生成颜色，并采用数字图像处理的方法对于原本的图像进行填充
2. 涂鸦上色问题就转化为了一个从边缘图像恢复原本的彩色图像的问题，采用pix2pix(基于条件生成对抗神经网络)的算法进行学习。

#### 图像填充

由于涂鸦的特殊性，我采用漫水算法进行填充

* 逐个搜索图像中的点
* 如果该点和白色颜色很接近，则选取为待填充的点
* 随机选取颜色，并手动调高饱和度(看起来更加和谐)，将该点填充为这个颜色
* 查看该点周围的8个点，回到第二步，如果均没有，则回到第一步
* 在所有的点均填充过后，用白色填充左上角的点，去除背景的颜色

#### pix2pix算法

作为一个从图像到图像的(图像翻译)算法，pix2pix使用条件生成对抗网络来学习输入图像和输出图像的一一映射，该网络由两部分组成。

##### Generator(生成器)

生成器利用一些变换从输入图像获得输出图像，在通常的实现中，生成器的部分是由一系列的编码器(卷积+激活函数)以及解码器(反卷积+激活函数)实现，具体的示意图如下：

![](http://osv1xytac.bkt.clouddn.com/18-6-10/45902206.jpg)

##### 鉴别器

鉴别器对于发生器输出的图像以及原本的标注好的图像进行猜测，猜测该图像是否是由发生器输出的。具体网络结构如下：
![](http://osv1xytac.bkt.clouddn.com/18-6-10/62686003.jpg)

该方法的优势在于鉴别器自动提供了我们用来训练发生器的损失函数，而不是需要我们自己手动指定，就相当于损失函数的部分由另一个神经网络的训练过程取代，并且效果同样很优秀。

##### 训练流程

训练该网络有两个步骤：

* 训练鉴别器：首先使用生成器输出图像，鉴别器则负责查看该图像与真实图像，并且对于图像的相似度，做出猜测，然后利用该数据来调整鉴别器的权重。
* 训练生成器：根据鉴别器的输出以及输出和目标图像之间的差异调整生成器的权重

最终的理想结果是生成器以及鉴别器的结果都变得越来越好。

#### 实验结果

##### 数字图像处理方法
![](http://osv1xytac.bkt.clouddn.com/18-6-10/85233950.jpg)
![](http://osv1xytac.bkt.clouddn.com/18-6-10/49609570.jpg)

##### pix2pix方法：
由于数据集难于寻找，最终采用的街道-真实街道的背景数据效果不高，结果如下：
![](http://osv1xytac.bkt.clouddn.com/18-6-10/58548392.jpg)


